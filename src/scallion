#!/usr/bin/env python2.7

import os, sys, subprocess, shutil, gzip, argparse, pygeoip, random, socket
from datetime import datetime
from time import sleep

INSTALL_PREFIX="/usr/local"

def main():
    # setup our commands
    pmain = argparse.ArgumentParser(description='Utility to assist in setting up scallion plug-in experiments for shadow', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    spmain = pmain.add_subparsers(help='run a subcommand (for help use <subcommand> --help)')
    pgenerate = spmain.add_parser('generate', help='Generate Tor-style topologies for the scallion plugin to the shadow simulator. You should run this generator in the directory from which you plan to run shadow, and give correct paths to the required files.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    pgenerate.set_defaults(func=generate)
    prun = spmain.add_parser('run', help="Run a Tor experiment using previously generated settings", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    prun.set_defaults(func=run)
    pauto = spmain.add_parser('auto', help="Generate and run a Tor experiment using default settings", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    pauto.set_defaults(func=auto)
    pclean = spmain.add_parser('clean', help="Clean data directory from previously generated settings", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    pclean.set_defaults(func=clean)
    
    ## MAIN
    pmain.add_argument('-q', '--quiet', action="store_true", dest="be_quiet",
          help="this script will not display its actions", default=False)

    ## GENERATE
    pgenerate.add_argument('-p', '--prefix', action="store", dest="prefix",
          help="PATH to scallion installation", metavar="PATH", default=INSTALL_PREFIX)
        
    # network configuration
    pgenerate.add_argument('--nrelays', action="store", type=int, dest="nrelays",
          help="number of total relays for the generated topology", metavar='N', default=40)
    pgenerate.add_argument('--fexit', action="store", type=float, dest="exitfrac",
          help="fraction of relays that are exits", metavar='F', default=0.4)
    pgenerate.add_argument('--nclients', action="store", type=int, dest="nclients",
          help="number of total clients for the generated topology", metavar='N', default=2640)
    pgenerate.add_argument('--fbulk', action="store", type=float, dest="fbulk",
          help="fraction of bulk downloading clients (remaining are web clients)", metavar='F', default=0.05)
    pgenerate.add_argument('--nservers', action="store", type=int, dest="nfs",
          help="number of fileservers", metavar='N', default=200)

    # torrc configuration files
    pgenerate.add_argument('--exit', action="store", type=str, dest="exitrc",
          help="custom path to a torrc for exit Tor relays", metavar='PATH', default=None)
    pgenerate.add_argument('--relay', action="store", type=str, dest="relayrc",
          help="custom path to a torrc for nonexit Tor relays", metavar='PATH', default=None)
    pgenerate.add_argument('--client', action="store", type=str, dest="clientrc",
          help="custom path to a torrc for Tor clients", metavar='PATH', default=None)
    pgenerate.add_argument('--authority', action="store", type=str, dest="authrc",
          help="custom path to a torrc for the Tor directory authority", metavar='PATH', default=None)
    
    pgenerate.add_argument('--authority-keys', action="store", type=str, dest="keys",
          help="custom path to Tor directory authority keys directory (This can be created with the command\n\"tor --list-fingerprint --DataDirectory . -f authkeys.torrc\"\nwhere authkeys.torrc contains\n\"DirServer test 127.0.0.1:5000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000\nORPort 5000\"", metavar='PATH/TO/AUTHORITY/KEYS', default=None)

    # other files
    pgenerate.add_argument('--consensus', action="store", type=str, dest="consensus",
          help="custom path to a Tor consensus file", metavar='PATH', default=None)
    pgenerate.add_argument('--geoip', action="store", type=str, dest="geoip",
          help="custom path to the Tor geoip file", metavar='PATH', default=None)
    pgenerate.add_argument('--geoipcity', action="store", type=str, dest="geoipcity",
          help="custom path to the Maxmind geoip city database needed for the pygeoip python module", metavar='PATH', default=None)
    
    pgenerate.add_argument('--output', action="store", type=str, dest="output",
          help="path to the output directory for files generated by this script and data produced in the simulation", metavar='PATH', default="scallion-output/")

    ## AUTO
    default_prefix = os.path.abspath(os.getenv("HOME") + "/.local/")
    pauto.add_argument('-p', '--prefix', action="store", dest="prefix",
          help="PATH to scallion installation", metavar="PATH", default=default_prefix)
    pauto.add_argument('--output', action="store", type=str, dest="output",
          help="path to the output directory for files generated by this script and data produced in the simulation", metavar='PATH', default="scallion-output/")
    
    ## RUN
    prun.add_argument('-p', '--prefix', action="store", dest="prefix",
          help="PATH to scallion installation", metavar="PATH", default=INSTALL_PREFIX)
    prun.add_argument('--output', action="store", type=str, dest="output",
          help="path to the output directory where files were generated", metavar='PATH', default="./")
   
    ## CLEAN
    pclean.add_argument('--output', action="store", type=str, dest="output",
          help="path to the output directory for files generated by this script and data produced in the simulation", metavar='PATH', default="./")

    # get arguments, accessible with args.value
    args = pmain.parse_args()
    # run chosen command
    retval = args.func(args)
    
    log("scallion returned " + str(retval))
    return

def generate(args):
    args.prefix = os.path.abspath(args.prefix)
    args.prefix2 = os.path.abspath(args.prefix + "/share/shadow/scallion/")
    
    # default paths from installation prefix
    if args.exitrc is None: args.exitrc = args.prefix2 + "/exit.torrc"
    if args.relayrc is None: args.relayrc = args.prefix2 + "/relay.torrc"
    if args.clientrc is None: args.clientrc = args.prefix2 + "/client.torrc"
    if args.authrc is None: args.authrc = args.prefix2 + "/authority.torrc"
    if args.keys is None: args.keys = args.prefix2 + "/authoritydata/keys"
    if args.consensus is None: args.consensus = args.prefix2 + "/consensus.txt"
    if args.geoip is None: args.geoip = args.prefix2 + "/geoip"
    if args.geoipcity is None: args.geoipcity = args.prefix2 + "/GeoLiteCity.dat"
    
    args.cdfs = args.prefix + "/share/shadow/resources"
    args.output = os.path.abspath(args.output)
    args.run = args.output
    args.data = os.path.abspath(args.output + "/data/")
    args.dsimout = os.path.abspath(args.output + "/scallion.dsim")
    args.www = args.prefix2
    
    args.exitrc = os.path.abspath(args.exitrc)
    args.relayrc = os.path.abspath(args.relayrc)
    args.clientrc = os.path.abspath(args.clientrc)
    args.authrc = os.path.abspath(args.authrc)
    args.keys = os.path.abspath(args.keys)
    args.consensus = os.path.abspath(args.consensus)
    args.geoip = os.path.abspath(args.geoip)
    args.geoipcity = os.path.abspath(args.geoipcity)
    args.run = os.path.abspath(args.run)
    args.cdfs = os.path.abspath(args.cdfs)
    args.data = os.path.abspath(args.data)
    args.dsimout = os.path.abspath(args.dsimout)
    
    if os.path.exists(args.output):
        log("Please specify an unused output directory with --output")
        return -1
    else: os.makedirs(args.output)
    
    os.chdir(args.output)
    os.makedirs(args.data)
    args.authoritydata = os.path.abspath(args.data + "/authoritydata/")
    args.exitdata = os.path.abspath(args.data + "/exitdata/")
    args.relaydata = os.path.abspath(args.data + "/relaydata/")
    args.clientdata = os.path.abspath(args.data + "/clientdata/")
    os.makedirs(args.authoritydata)
    os.makedirs(args.exitdata)
    os.makedirs(args.relaydata)
    os.makedirs(args.clientdata)
    
    shutil.copytree(args.keys, args.output+"/keys")
    shutil.copytree(args.keys, args.authoritydata + "/4uthority.scallion.shd/keys")
    
    shutil.copy(args.exitrc, args.output)
    args.exitrc = args.output + "/" + os.path.basename(args.exitrc)
    shutil.copy(args.relayrc, args.output)
    args.relayrc = args.output + "/" + os.path.basename(args.relayrc)
    shutil.copy(args.clientrc, args.output)
    args.clientrc = args.output + "/" + os.path.basename(args.clientrc)
    shutil.copy(args.authrc, args.output)
    args.authrc = args.output + "/" + os.path.basename(args.authrc)
    
    args.nbulk = float(args.nclients * args.fbulk)
    args.nweb = float(args.nclients - args.nbulk)
    if args.nweb < 0: args.nweb = 0

    se = ScallionExperiment(args)
    se.generate(args)
    
    return 0

class ScallionExperiment():
    def __init__(self, args):
        self.cp = ConsensusParser(args.consensus, args.geoipcity)
        self.select = self.cp.parse()
        self.outfile = open(args.dsimout, 'w')
        self.relay_choices = []
        self.choicefile = open(args.run + "/relay-choices.csv", 'w')

    def out(self, string):
        print >> self.outfile, string

    def generate(self, args):
        self.out(
"?DSIM3\n\
on(time 0:01){\n\
\tfs_plugin = load_plugin(\""+args.prefix+"/lib/libshadow-plugin-fileserver.so\");\n\
\tscallion_plugin = load_plugin(\""+args.prefix+"/lib/libshadow-plugin-scallion.so\");\n\
}\n\
\n\
on(time 0:02){\n\
\tfastbw_cdf = generate_cdf(102400, 0, 0);\n\
\tmidbw_cdf = generate_cdf(10240, 0, 0);\n\
\tslowupbw_cdf = generate_cdf(1024, 0, 0);\n\
\tslowdownbw_cdf = generate_cdf(3584, 0, 0);\n\
\tnormbw_cdf = load_cdf(\"" + args.cdfs + "/synthetic_bandwidth_KiBps.cdf\");\n\
\n\
\tfs_hostname = create_hostname(\"fileserver.shd\");\n\
\tauthority_hostname = create_hostname(\"4uthority.scallion.shd\");\n\
\trelay_hostname = create_hostname(\"relay.shd\");\n\
\texit_hostname = create_hostname(\"exit.shd\");\n\
\tproxy_hostname = create_hostname(\"proxy.shd\");\n\
\n\
\tlatency_cdf = generate_cdf(100, 0, 0);\n\
\n\
\tcpu_cdf = load_cdf(\"" + args.cdfs + "/synthetic_cpu_speed_arcachon_Bps.cdf\");")

        self.out("}\n\non(time 0:03){")
        # get all latency cdfs
        for region1 in self.cp.sg.shadowregions:
            for region2 in self.cp.sg.shadowregions:
                self.out("\t" + region1.name + "_to_" + region2.name + "_latency_cdf = load_cdf(\"" + args.cdfs + "/plab_latency/" + region1.name + "_to_" + region2.name + ".cdf\");")
        
        self.out("}\n\non(time 0:04){")

        # get all networks
        for region in self.cp.sg.shadowregions:
            self.out("\t" + region.name + "_network = create_network(" + region.name + "_to_" + region.name + "_latency_cdf, 1.0);")
#            self.out("\t" + region.name + "_network = create_network(latency_cdf, 1.0);")

        self.out("}\n\non(time 0:05){")

        # connect all networks
        for region1 in self.cp.sg.shadowregions:
            for region2 in self.cp.sg.shadowregions:
                if region1 != region2:
                    self.out("\tconnect_networks(" + region1.name + "_network, " + region1.name + "_to_" + region2.name + "_latency_cdf, 1.0, " + region2.name + "_network, " + region2.name + "_to_" + region1.name + "_latency_cdf, 1.0);")
#                    self.out("\tconnect_networks(" + region1.name + "_network, latency_cdf, 1.0, " + region2.name + "_network, latency_cdf, 1.0);")

        # start up the authority and file servers
        self.out("}\n\non(time 1:00){\n\
\tcreate_nodes(1, scallion_plugin, US_CENTRAL_network, authority_hostname, fastbw_cdf, NULL, cpu_cdf, \n\
\t\t\"dirauth 102400 " + args.authrc + " " + args.authoritydata + " " + args.geoip + "\");\n")

        # spread out the servers geographically
        networks = ["US_WEST_network", "US_CENTRAL_network", "US_EAST_network", "EU_WEST_network"]
        for network in networks:
            self.out("\tcreate_nodes(" + str(args.nfs/len(networks)) + ", fs_plugin, " + network + ", fs_hostname, fastbw_cdf, NULL, cpu_cdf, \"8080 " + args.www + "\");")

        remain = args.nfs%len(networks)
        if remain > 0:
            self.out("\tcreate_nodes(" + str(remain) + ", fs_plugin, US_CENTRAL_network, fs_hostname, fastbw_cdf, NULL, cpu_cdf, \"8080 " + args.www + "\");\n")

        self.out("}\n")

        # the clients will need to know which servers to connect to
        f = open(args.run + "/bulk.spec", 'w')
        for i in range(args.nfs):
            if i == 0: print >> f, "fileserver.shd:8080:/5MiB.urnd"
            else: print >> f, str(i) + ".fileserver.shd:8080:/5MiB.urnd"
        f.close()
        f = open(args.run + "/web.spec", 'w')
        for i in range(args.nfs):
            if i == 0: print >> f, "fileserver.shd:8080:/320KiB.urnd"
            else: print >> f, str(i) + ".fileserver.shd:8080:/320KiB.urnd"
        f.close()

        total_bw = 0.0;
        # start the exits first
        exits = self.select.exits(int(args.nrelays * args.exitfrac))
        for e in exits: self.relay_choices.append(e)
        each = len(exits)/5
        remain = len(exits)%5

        if each != 0:
            for i in xrange(60, 210, 30):
                self.out("on(time " + str(i) + ":00){")
                for j in xrange(each):
                    exit = exits.pop()
                    total_bw += exit.torbw
                    self.out(
#"\trelay_" + exit.ip + "_bw_cdf = generate_cdf(" + str(exit.bw) + ", 0, 0);\n\
"\tcreate_nodes(1, scallion_plugin, " + exit.georegion + "_network, exit_hostname, " + self.getbwstr(exit.torbw) + ", " + self.getbwdownstr(exit.torbw) + ", cpu_cdf,\n\
\t\t\"exitrelay " + str(exit.torbw) + " " + args.exitrc + " " + args.exitdata + " " + args.geoip + "\");")
                self.out("}\n")

        if len(exits) > 0:
            self.out("on(time 210:00){")
            while len(exits) > 0:
                exit = exits.pop()
                total_bw += exit.torbw
                self.out(
#"\trelay_" + exit.ip + "_bw_cdf = generate_cdf(" + str(exit.bw) + ", 0, 0);\n\
"\tcreate_nodes(1, scallion_plugin, " + exit.georegion + "_network, exit_hostname, " + self.getbwstr(exit.torbw) + ", " + self.getbwdownstr(exit.torbw) + ", cpu_cdf,\n\
\t\t\"exitrelay " + str(exit.torbw) + " " + args.exitrc + " " + args.exitdata + " " + args.geoip + "\");")
            self.out("}\n")

        # now start the other relays
        relays = self.select.relays(int(args.nrelays - (args.nrelays * args.exitfrac)))
        for r in relays: self.relay_choices.append(r)
        each = len(relays)/5
        remain = len(relays)%5

        if each != 0:
            for i in xrange(240, 390, 30):
                self.out("on(time " + str(i) + ":00){")
                for j in xrange(each):
                    relay = relays.pop()
                    total_bw += relay.torbw
                    self.out(
#"\trelay_" + relay.ip + "_bw_cdf = generate_cdf(" + str(relay.bw) + ", 0, 0);\n\
"\tcreate_nodes(1, scallion_plugin, " + relay.georegion + "_network, relay_hostname, " + self.getbwstr(relay.torbw) + ", " + self.getbwdownstr(relay.torbw) + ", cpu_cdf,\n\
\t\t\"relay " + str(relay.torbw) + " " + args.relayrc + " " + args.relaydata + " " + args.geoip + "\");")
                self.out("}\n")

        if len(relays) > 0:
            self.out("on(time 390:00){")
            while len(relays) > 0:
                relay = relays.pop()
                total_bw += relay.torbw
                self.out(
#"\trelay_" + relay.ip + "_bw_cdf = generate_cdf(" + str(relay.bw) + ", 0, 0);\n\
"\tcreate_nodes(1, scallion_plugin, " + relay.georegion + "_network, relay_hostname, " + self.getbwstr(relay.torbw) + ", " + self.getbwdownstr(relay.torbw) + ", cpu_cdf,\n\
\t\t\"relay " + str(relay.torbw) + " " + args.relayrc + " " + args.relaydata + " " + args.geoip + "\");")
            self.out("}\n")

        # give time for bootstrapping before the clients
        each_web = int(args.nweb / 30)
        remain_web = int(args.nweb % 30)
        each_bulk = int(args.nbulk / 30)
        remain_bulk = int(args.nbulk % 30)

        WEB=" multi " + args.run + "/web.spec localhost 9000 " + args.cdfs + "/think_times_ms.cdf -1"
        BULK=" multi " + args.run + "/bulk.spec localhost 9000 none -1"

        for i in xrange(1200, 1500, 10):
            self.out("on(time " + str(i) + ":00){")
            self.out(
"\tcreate_nodes(" + str(each_web) + ", scallion_plugin, " + self.cp.sg.random_region() + "_network, proxy_hostname, slowupbw_cdf, slowdownbw_cdf, cpu_cdf,\n\
\t\t\"client 102400 " + args.clientrc + " " + args.clientdata + " " + args.geoip + WEB + "\");\n");

            ncreate = each_bulk;
            if ncreate == 0 and remain_bulk > 0:
                ncreate = 1
                remain_bulk -= 1
            if ncreate > 0:
                self.out("\tcreate_nodes(" + str(ncreate) + ", scallion_plugin, " + self.cp.sg.random_region() + "_network, proxy_hostname, slowupbw_cdf, slowdownbw_cdf, cpu_cdf,\n\
\t\t\"client 102400 " + args.clientrc + " " + args.clientdata + " " + args.geoip + BULK + "\");")

            self.out("}\n")

        if remain_web > 0 or remain_bulk > 0:
            self.out("on(time 1500:00){")
            if remain_web > 0:
                self.out(
"\tcreate_nodes(" + str(remain_web) + ", scallion_plugin, " + self.cp.sg.random_region() + "_network, proxy_hostname, slowupbw_cdf, slowdownbw_cdf, cpu_cdf,\n\
\t\t\"client 102400 " + args.clientrc + " " + args.clientdata + " " + args.geoip + WEB + "\");")
            if remain_bulk > 0:
                self.out(
"\tcreate_nodes(" + str(remain_bulk) + ", scallion_plugin, " + self.cp.sg.random_region() + "_network, proxy_hostname, slowupbw_cdf, slowdownbw_cdf, cpu_cdf,\n\
\t\t\"client 102400 " + args.clientrc + " " + args.clientdata + " " + args.geoip + BULK + "\");")
            self.out("}\n")

        self.out("on(time 4980:00) {end();}")


        # check out what we generated
        nlive_relays = float(len(self.select.liverelays) + len(self.select.liveexits))
        live_bw = self.cp.total_live_bw
        ngen_relays = float(args.nrelays)
        gen_bw = total_bw
        gen_fraction = gen_bw/live_bw
        expected_fraction = ngen_relays/nlive_relays

        chosen_bws = [r.torbw for r in self.relay_choices]
        chosen_bws.sort()
        median_chosen = chosen_bws[int(len(chosen_bws)/2)]

        print >> sys.stderr, "live Tor has " + str(nlive_relays) + " relays with " + str(live_bw) + " total bandwidth"
        print >> sys.stderr, "generated " + str(ngen_relays) + " relays with " + str(gen_bw) + " total bandwidth"
        print >> sys.stderr, "bandwidth is " + str(gen_fraction * 100.0) + "% of live Tor, using " + str(expected_fraction * 100.0) + "% of the relays"
        print >> sys.stderr, "chosen relay bandwidth median: " + str(median_chosen) + ", and mean: " + str(gen_bw/ngen_relays)
#        diff = gen_fraction - expected_fraction
#        div = gen_fraction / expected_fraction
#        if diff > 0.01 or diff < -0.01 or div > 2 or div < 0.5: print >> sys.stderr, "you might want to try again"

        print >> sys.stderr, "see " + args.run + "/relay_choices.csv for relay choice info"

        print >> self.choicefile,  "#ip,bandwidth(KBps),geocode,georegion,isExit"
        for r in self.relay_choices:
            print >> self.choicefile, r.toCSV()

    def dump(self):
        print "#ip,bandwidth(KBps),geocode,georegion,isExit"
        for r in self.select.liverelays:
            print r.toCSV()

    def getbwstr(self, torbw):
        if torbw <= 1024.0 : return "slowupbw_cdf"
        elif torbw <= 10240.0: return "midbw_cdf"
        else: return "fastbw_cdf"

    def getbwdownstr(self, torbw):
        if torbw <= 1024.0 : return "slowdownbw_cdf"
        elif torbw <= 10240.0: return "midbw_cdf"
        else: return "fastbw_cdf"

    def getlatencystr(self, name1, name2):
        return "latency_cdf"

class Relay():
    def __init__(self, ip, torbw, shadowgeocode, shadowregion, isExit=False):
        self.ip = ip.replace(".", "_")
        self.torbw = torbw
        """ 
account for shadow network overhead. actual connections are faster than what they are giving to Tor.
our headers are 40 bytes. so if we want Tor to get X bandwidth, we need to give our node:
    protocol_overhead = 40/1500
    newbw = bw + (bw * protocol_overhead)
or simply:
    newbw = (1540/1500)*bw
we also add 20 KB for burst.
        """
        self.bw = (torbw * (1540.0/1500.0)) + 20
        self.isExit = isExit
        self.geocode = shadowgeocode
        self.georegion = shadowregion

    def toCSV(self):
        return ",".join([self.ip.replace("_","."), str(self.torbw), self.geocode, self.georegion, str(self.isExit)])

class RelaySelection():
    def __init__(self, allrelays):
        self.liverelays, self.liveexits, self.cutrelays, self.cutexits = [], [], [], []
        self.cutrelays_deciles, self.cutexits_deciles = {}, {}

        for r in allrelays:
            if r.isExit: self.liveexits.append(r)
            else: self.liverelays.append(r)
            if r.torbw > 20:
                if r.isExit: self.cutexits.append(r)
                else: self.cutrelays.append(r)

        self.cutrelays.sort(key=lambda x: x.torbw, reverse=True)
        self.cutexits.sort(key=lambda x: x.torbw, reverse=True)

        n = len(self.cutrelays)/10
        j = -1
        for i in xrange(len(self.cutrelays)):
            if i % (len(self.cutrelays)/10) == 0: j+=1
            if j not in self.cutrelays_deciles: self.cutrelays_deciles[j] = []
            self.cutrelays_deciles[j].append(self.cutrelays[i])
        n = len(self.cutexits)/10
        j = -1
        for i in xrange(len(self.cutexits)):
            if i % (len(self.cutexits)/10) == 0: j+=1
            if j not in self.cutexits_deciles: self.cutexits_deciles[j] = []
            self.cutexits_deciles[j].append(self.cutexits[i])  

    def exits(self, num):
        exits = []
        i = 0
        for j in xrange(num):
            dlist = self.cutexits_deciles[i]
            exits.append(random.choice(dlist))
            i += 1
            if i == 10: i = 0
        return exits

    def relays(self, num):
        relays = []
        i = 0
        for j in xrange(num):
            dlist = self.cutrelays_deciles[i]
            relays.append(random.choice(dlist))
            i += 1
            if i == 10: i = 0
        return relays       

class ConsensusParser():
    def __init__(self, consensus_path, geoipcity):
        self.sg = ShadowGeo(geoipcity)
        self.consensus = consensus_path
        self.total_live_bw = 0

    def parse(self):
        relays = []
        ip = ""
        bw = 0.0
        isExit = False
        f = open(self.consensus)
        for line in f:
            if line[0:2] == "r ":
                # append the relay that we just built up
                if ip != "": 
                    code = self.sg.address_to_shadowgeocode(ip)
                    region = self.sg.shadowgeocode_to_shadowregion(code)
                    if region is None: print "!W: cant find region for code: " + code
                    else:
                        self.total_live_bw += bw
                        r = Relay(ip, bw, code, region, isExit)                 
                        relays.append(r)
                # reset for the next relay
                bw = 0.0
                isExit = False
                ip = line.strip().split()[6]
            elif line[0:2] == "s ":
                if line.strip().split()[1] == "Exit": isExit = True
            elif line[0:2] == "w ":
                bw = float(line.strip().split()[1].split("=")[1])
        f.close()
        return RelaySelection(relays)

"""
This class handles conversions from ip and hostnames to regions defined in shadow.
This is useful for generating a network with latencies that somewhat reflect the real-world.

Dependencies:

pygeoip : http://code.google.com/p/pygeoip/
usage: http://code.google.com/p/pygeoip/wiki/Usage

Also need maxmind geoip database. They are different sizes because they offer different
ammounts of information:
http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz
http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz
http://geolite.maxmind.com/download/geoip/database/asnum/GeoIPASNum.dat.gz

"""

class ShadowGeo():
    US_WEST = ["WA", "ID", "MT", "WY", "OR", "NV", "CA", "UT", "CO", "NM", "AZ", "HI"]
    US_CENTRAL = ["ND", "MN", "WI", "SD", "IA", "IL", "NE", "KS", "MO", "OK", "AR", "LA", "TX", "MI", "IN", "OH", "KY", "TN", "MS", "US"]
    US_EAST = ["AL", "GA", "FL", "SC", "NC", "VA", "WV", "PA", "NY", "VT", "NH", "ME", "MA", "RI", "CT", "NJ", "DE", "MD", "DC"]
    NORTH = ["CA", "AK"]
    SOUTH = ["BR", "VE", "AR", "UY", "AQ", "BB", "RE", "CI", "CL", "EG", "ZA", "CR"]
    EU_WEST = ["BE", "FR", "DE", "HU", "FI", "NL", "PT", "NO", "AT", "RO", "PL", "CH", "GR", "IT", "CZ", "IE", "ES", "SE", "GB", "LU", "EE", "HR", "DK", "BG", "BA", "JE", "BY", "LV", "LT", "SK", "UA", "SI", "EU"]
    EU_EAST = ["JO", "RU", "TR", "PK", "IL", "GE", "SA"]
    ASIA = ["JP", "HK", "TW", "CN", "KR", "SG", "VN", "TH", "MY"]
    AUSTRALIA = ["NZ", "AU", "MX"]

    def __init__(self, geoipcity_path="/usr/local/share/GeoIP/GeoIPCity.dat"):
        self.geoip = pygeoip.GeoIP(geoipcity_path)
        self.shadowregions = list()
        self.shadowregions.append(ShadowRegion("US_WEST", ShadowGeo.US_WEST))
        self.shadowregions.append(ShadowRegion("US_CENTRAL", ShadowGeo.US_CENTRAL))
        self.shadowregions.append(ShadowRegion("US_EAST", ShadowGeo.US_EAST))
        self.shadowregions.append(ShadowRegion("NORTH", ShadowGeo.NORTH))
        self.shadowregions.append(ShadowRegion("SOUTH", ShadowGeo.SOUTH))
        self.shadowregions.append(ShadowRegion("EU_WEST", ShadowGeo.EU_WEST))
        self.shadowregions.append(ShadowRegion("EU_EAST", ShadowGeo.EU_EAST))
        self.shadowregions.append(ShadowRegion("ASIA", ShadowGeo.ASIA))
        self.shadowregions.append(ShadowRegion("AUSTRALIA", ShadowGeo.AUSTRALIA))

        self.shadowgeocode_shadowregion_map = dict()
        for sr in self.shadowregions:
            for c in sr.children:
                self.shadowgeocode_shadowregion_map[c] = sr.name

    def _record_to_shadowgeocode(self, record):
        rn = record['region_name']
        cc = record['country_code']
        if cc == "US" and rn != "": cc = rn
        return cc

    def address_to_shadowgeocode(self, address):
        record = self.region_by_addr(address)
        return self._record_to_shadowgeocode(record)

    def hostname_to_shadowgeocode(self, hostname):
        record = self.region_by_name(hostname)
        return self._record_to_shadowgeocode(record)

    def shadowgeocode_to_shadowregion(self, shadowgeocode):
        if shadowgeocode not in self.shadowgeocode_shadowregion_map: return None
        else: return self.shadowgeocode_shadowregion_map[shadowgeocode]

    def address_to_shadowregion(self, address):
        return self.shadowgeocode_to_shadowregion(self.address_to_shadowgeocode(address))

    def hostname_to_shadowregion(self, hostname):
        return self.shadowgeocode_to_shadowregion(self.hostname_to_shadowgeocode(hostname))

    def random_region(self):
        return random.choice(self.shadowregions).name

    def region_by_name(self, hostname):
        addr = socket.gethostbyname(hostname)
        return self.region_by_addr(addr)

    def region_by_addr(self, address):
        ipnum = self.ip2long(address)
        rec = self.geoip._get_record(ipnum)
        country_code, region = "", ""
        if 'country_code' in rec: country_code = rec['country_code'] 
        if 'region_name' in rec: region = rec['region_name']
        return {'country_code' : country_code, 'region_name' : region }

    def ip2long(self, ip):
        """
        Convert a IPv4 address into a 32-bit integer.
        
        @param ip: quad-dotted IPv4 address
        @type ip: str
        @return: network byte order 32-bit integer
        @rtype: int
        """
        ip_array = ip.split('.')
        ip_long = long(ip_array[0]) * 16777216 + long(ip_array[1]) * 65536 + long(ip_array[2]) * 256 + long(ip_array[3])
        return ip_long

class ShadowRegion():
     def __init__(self, name, childlist):
        self.name = name
        self.children = set()
        for child in childlist:
            if child not in self.children: self.children.add(child)

     def contains(self, child):
        if child in self.children: return True
        else: return False
    
def run(args):
    os.chdir(args.output)
    logfilepath = "data/scallion.log"
    if os.path.exists(logfilepath):
        log("Logfile already exists. It appears you have already run an experiment. Please copy important data, then clean the data directory with the --clean command")
        return -1
    
    # start monitoring, if dstat is in the path
    dstat_cmd = "dstat -cmstTy --fs --output data/dstat.log"
    dstat_p = None
    try: dstat_p = subprocess.Popen(dstat_cmd.split(), stdout=open("/dev/null", 'w'))
    except: dstat_p = None
        
    # run
    cmd = os.path.abspath(args.prefix+"/bin/shadow")+" run -p 1 -d scallion.dsim -l " + os.path.abspath(args.prefix+"/lib/libshadow-plugin-scallion-preload.so")

    log("calling " + cmd + " with logfile " + logfilepath)

    f = open(logfilepath, 'w')
    start = datetime.now()
    retcode = subprocess.call(cmd.split(), stdout=f)
    end = datetime.now()
    f.close()

    if dstat_p is not None: dstat_p.kill()

    log(str(end) + " shadow returned " + str(retcode) + " in " + str(end-start) + " seconds")

def auto(args):
    args.prefix = os.path.abspath(os.getenv("HOME") + "/.local/")
    args.nrelays = 40
    args.exitfrac = 0.4
    args.nclients = 2640
    args.fbulk = 0.05
    args.nfs = 200
    args.exitrc = None
    args.relayrc = None
    args.clientrc = None
    args.authrc = None
    args.keys = None
    args.consensus = None
    args.geoip = None
    args.geoipcity = None
    
    retval = generate(args)
    if retval == 0:
        os.chdir(args.output)
        retval = run(args)
    return retval

def clean(args):
    args.output = os.path.abspath(args.output)
    if os.path.exists(args.output+"/data"): shutil.rmtree(args.output+"/data")
    
    os.makedirs(args.output+"/data/authoritydata")
    os.makedirs(args.output+"/data/exitdata")
    os.makedirs(args.output+"/data/relaydata")
    os.makedirs(args.output+"/data/clientdata")
    
    shutil.copytree(args.output+"/keys", args.output+"/data/authoritydata/4uthority.scallion.shd/keys")
    return 0

def dd(filename, kb):
    if not os.path.exists(filename):
        ddcmd = "/bin/dd if=/dev/urandom of=" + filename + " bs=1024 count=" + str(kb)
        log("calling " + ddcmd)
        subprocess.call(ddcmd.split())

def log(msg):
    color_start_code = "\033[94m" # red: \033[91m"
    color_end_code = "\033[0m"
    prefix = "[" + str(datetime.now()) + "] setup: "
    print >> sys.stderr, color_start_code + prefix + msg + color_end_code

if __name__ == '__main__':
    main()